% Encoding: UTF-8

@Conference{Sculley2015,
  author     = {D. Sculley and Gary Holt and Daniel Golovin and Eugene Davydov and Todd Phillips and Dietmar Ebner and Vinay Chaudhary and Michael Young and Jean-François Crespo and Dan Dennison},
  booktitle  = {Advances in Neural Information Processing Systems},
  title      = {Hidden Technical Debt in Machine Learning Systems},
  year       = {2015},
  editor     = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
  volume     = {28},
  abstract   = {Machine learning offers a fantastically powerful toolkit for building useful complexprediction systems quickly. This paper argues it is dangerous to think ofthese quick wins as coming for free. Using the software engineering frameworkof technical debt, we find it is common to incur massive ongoing maintenancecosts in real-world ML systems. We explore several ML-specific risk factors toaccount for in system design. These include boundary erosion, entanglement,hidden feedback loops, undeclared consumers, data dependencies, configurationissues, changes in the external world, and a variety of system-level anti-patterns.},
  comment    = {Discusses various types of technical debt specific to (or especially prominent in) ML systems:
- Complex models erode boundaries
   -  Entanglement
      - Changing anything changes everything
   - Correction cascades
      - Model interdependency
- Undeclared consumers (visibility debt)
   - Don’t know about consumers of data
- Data dependencies cost more than code dependencies
   - Unstable data dependencies
   - Underutilized data dependencies
- Feedback loops
   - Direct feedback loops
   - Hidden feedback loops
- ML-system antipatterns
   - Glue code
   - Pipeline jungles
   - Dead experimental code paths
   - Abstraction debt
- Common smells:
   - Plain-Old-Data type smell
   - Multiple-language smell
   - Prototype smell
- Configuration debt
- Dealing with changes in the external world
   - Fixed thresholds in dynamic systems
   - Monitoring and testing
      - Prediction bias
      - Action limits
      - Up-stream producers
- Other areas of ml-related debt:
   - Data testing debt
   - Reproducibility debt
   - Process management debt
   - Cultural debt},
  keywords   = {background},
  ranking    = {rank5},
  readstatus = {read},
}

@Article{Paleyes2020,
  author        = {Andrei Paleyes and Raoul-Gabriel Urma and Neil D. Lawrence},
  journal       = {The ML-Retrospectives, Surveys \& Meta-Analyses Workshop, NeurIPS 2020},
  title         = {Challenges in Deploying Machine Learning: a Survey of Case Studies},
  year          = {2020},
  month         = nov,
  abstract      = {In recent years, machine learning has received increased interest both as an academic research field and as a solution for real-world business problems. However, the deployment of machine learning models in production systems can present a number of issues and concerns. This survey reviews published reports of deploying machine learning solutions in a variety of use cases, industries and applications and extracts practical considerations corresponding to stages of the machine learning deployment workflow. Our survey shows that practitioners face challenges at each stage of the deployment. The goal of this paper is to layout a research agenda to explore approaches addressing these challenges.},
  archiveprefix = {arXiv},
  comment       = {- objective: map out challenges in ML deployment among practitioners
- only includes case studies
   - good for getting in-depth practitioner perspective, but not comprehensive enough for an MLR

include data validation in ml pipeline

Monitoring of evolving input data, prediction bias and overall performance of ML models is an open problem.

end-to-end platforms do not fit needs well because the final ML solution is so sensitive to the problem particulars

there is an overlap between choice of metrics for monitoring and validation},
  eid           = {arXiv:2011.09926},
  eprint        = {2011.09926},
  file          = {:http\://arxiv.org/pdf/2011.09926v2:PDF},
  keywords      = {cs.LG, related},
  primaryclass  = {cs.LG},
  priority      = {prio2},
  readstatus    = {skimmed},
  relevance     = {relevant},
  url           = {https://ui.adsabs.harvard.edu/abs/2020arXiv201109926P},
}

@Article{Leite2020,
  author    = {Leonardo Leite and Carla Rocha and Fabio Kon and Dejan Milojicic and Paulo Meirelles},
  journal   = {{ACM} Computing Surveys},
  title     = {A Survey of {DevOps} Concepts and Challenges},
  year      = {2020},
  issn      = {0360-0300},
  month     = {jan},
  number    = {6},
  pages     = {1--35},
  volume    = {52},
  abstract  = {DevOps is a collaborative and multidisciplinary organizational effort to automate continuous delivery of new software updates while guaranteeing their correctness and reliability. The present survey investigates and discusses DevOps challenges from the perspective of engineers, managers, and researchers. We review the literature and develop a DevOps conceptual map, correlating the DevOps automation tools with these concepts. We then discuss their practical implications for engineers, managers, and researchers. Finally, we critically explore some of the most relevant DevOps challenges reported by the literature.},
  doi       = {10.1145/3359981},
  keywords  = {background},
  publisher = {Association for Computing Machinery ({ACM})},
}

@InCollection{John2021,
  author     = {Meenu Mary John and Helena Holmström Olsson and Jan Bosch},
  booktitle  = {Lecture Notes in Business Information Processing},
  publisher  = {Springer International Publishing},
  title      = {Architecting AI Deployment: A Systematic Review of State-of-the-Art and State-of-Practice Literature},
  year       = {2021},
  pages      = {14--29},
  abstract   = {Companies across domains are rapidly engaged in shifting computational power and intelligence from centralized cloud to fully decentralized edges to maximize value delivery, strengthen security and reduce latency. However, most companies have only recently started pursuing this opportunity and are therefore at the early stage of the cloud-to-edge transition. To provide an overview of AI deployment in the context of edge/cloud/hybrid architectures, we conduct a systematic literature review and a grey literature review. To advance understanding of how to integrate, deploy, operationalize and evolve AI models, we derive a framework from existing literature to accelerate the end-to-end deployment process. The framework is organized into five phases: Design, Integration, Deployment, Operation and Evolution. We make an attempt to analyze the extracted results by comparing and contrasting them to derive insights. The contribution of the paper is threefold. First, we conduct a systematic literature review in which we review the contemporary scientific literature and provide a detailed overview of the state-of-the-art of AI deployment. Second, we review the grey literature and present the state-of-practice and experience of practitioners while deploying AI models. Third, we present a framework derived from existing literature for the end-to-end deployment process and attempt to compare and contrast SLR and GLR results.},
  comment    = {- apparent objective of the paper:
  - conduct MLR in order to:
    - create a framework with steps for deploying models in the SOTA
    - map out current challenges
- does not review or mention earlier literature reviews in the field
- draws upon both white and grey literature
  - thirteen examples of white literature included
  - only six examples of grey literature included
  - somewhat arbitrary filtering, ("selected 6 of 16 that benefited our research")


Differences from my paper:
- Less GL coverage
- Some arbitrary/undocumented filtering decisions
- Focuses on creating a high level framework for all steps the MLOps pipeline},
  doi        = {10.1007/978-3-030-67292-8_2},
  issn       = {1865-1348},
  keywords   = {related},
  priority   = {prio1},
  ranking    = {rank3},
  readstatus = {skimmed},
  relevance  = {relevant},
}

@InCollection{Soh2020,
  author    = {Julian Soh and Priyanshi Singh},
  booktitle = {Data Science Solutions on Azure},
  publisher = {Apress},
  title     = {Machine Learning Operations},
  year      = {2020},
  pages     = {259--279},
  abstract  = {Machine learning operations (MLOps) is DevOps for machine learning processes. MLOps enables data scientists to collaborate and increase the pace of delivery and quality of model development through monitoring, validation, and governance of machine learning models. This is equivalent to how DevOps helps software engineers develop, test, and deploy software quicker and with fewer defects. MLOps supports the data science life cycle just as DevOps supports the application development life cycle. As such, MLOps is based on the principles of DevOps.},
  doi       = {10.1007/978-1-4842-6405-8_8},
  keywords  = {background},
}

@Article{Giray2021,
  author     = {Görkem Giray},
  journal    = {Journal of Systems and Software},
  title      = {A software engineering perspective on engineering machine learning systems: State of the art and challenges},
  year       = {2021},
  month      = {oct},
  pages      = {111031},
  volume     = {180},
  abstract   = {Context:

Advancements in machine learning (ML) lead to a shift from the traditional view of software development, where algorithms are hard-coded by humans, to ML systems materialized through learning from data. Therefore, we need to revisit our ways of developing software systems and consider the particularities required by these new types of systems.
Objective:

The purpose of this study is to systematically identify, analyze, summarize, and synthesize the current state of software engineering (SE) research for engineering ML systems.
Method:

I performed a systematic literature review (SLR). I systematically selected a pool of 141 studies from SE venues and then conducted a quantitative and qualitative analysis using the data extracted from these studies.
Results:

The non-deterministic nature of ML systems complicates all SE aspects of engineering ML systems. Despite increasing interest from 2018 onwards, the results reveal that none of the SE aspects have a mature set of tools and techniques. Testing is by far the most popular area among researchers. Even for testing ML systems, engineers have only some tool prototypes and solution proposals with weak experimental proof. Many of the challenges of ML systems engineering were identified through surveys and interviews. Researchers should conduct experiments and case studies, ideally in industrial environments, to further understand these challenges and propose solutions.
Conclusion:

The results may benefit (1) practitioners in foreseeing the challenges of ML systems engineering; (2) researchers and academicians in identifying potential research questions; and (3) educators in designing or updating SE courses to cover ML systems engineering.},
  comment    = {SLR of SE for ML, where challenges and solutionswere grouped by areas suggested in SWEBOK, similarly to Kumeno and Nascimento, while including an even greater number of papers than any previous SLR in the field.},
  doi        = {10.1016/j.jss.2021.111031},
  keywords   = {related},
  priority   = {prio2},
  publisher  = {Elsevier {BV}},
  ranking    = {rank5},
  readstatus = {skimmed},
  relevance  = {relevant},
}

@Article{Enholm2021,
  author    = {Ida Merete Enholm and Emmanouil Papagiannidis and Patrick Mikalef and John Krogstie},
  journal   = {Information Systems Frontiers},
  title     = {Artificial Intelligence and Business Value: a Literature Review},
  year      = {2021},
  month     = {aug},
  abstract  = {Artificial Intelligence (AI) are a wide-ranging set of technologies that promise several advantages for organizations in terms off added business value. Over the past few years, organizations are increasingly turning to AI in order to gain business value following a deluge of data and a strong increase in computational capacity. Nevertheless, organizations are still struggling to adopt and leverage AI in their operations. The lack of a coherent understanding of how AI technologies create business value, and what type of business value is expected, therefore necessitates a holistic understanding. This study provides a systematic literature review that attempts to explain how organizations can leverage AI technologies in their operations and elucidate the value-generating mechanisms. Our analysis synthesizes the current literature and highlights: (1) the key enablers and inhibitors of AI adoption and use; (2) the typologies of AI use in the organizational setting; and (3) the first- and second-order effects of AI. The paper concludes with an identification of the gaps in the literature and develops a research agenda that identifies areas that need to be addressed by future studies.},
  doi       = {10.1007/s10796-021-10186-w},
  keywords  = {background},
  publisher = {Springer Science and Business Media {LLC}},
}

@Book{Oates2005,
  author    = {Oates, Briony J.},
  publisher = {Sage Publications},
  title     = {Researching Information Systems and Computing},
  year      = {2005},
  isbn      = {1412902231},
  month     = nov,
  ean       = {9781412902236},
  keywords  = {guidelines},
  pagetotal = {360},
  url       = {https://www.ebook.de/de/product/4909287/briony_j_oates_researching_information_systems_and_computing.html},
}

@Article{Garousi2019,
  author    = {Vahid Garousi and Michael Felderer and Mika V. Mäntylä},
  journal   = {Information and Software Technology},
  title     = {Guidelines for including grey literature and conducting multivocal literature reviews in software engineering},
  year      = {2019},
  issn      = {0950-5849},
  month     = {feb},
  pages     = {101--121},
  volume    = {106},
  doi       = {10.1016/j.infsof.2018.09.006},
  file      = {:papers/mlr_guidelines.pdf:PDF},
  keywords  = {guidelines},
  publisher = {Elsevier {BV}},
}

@Misc{Kitchenham07guidelinesfor,
  author   = {B. Kitchenham and S Charters},
  title    = {Guidelines for performing Systematic Literature Reviews in Software Engineering},
  year     = {2007},
  keywords = {guidelines},
}

@InProceedings{Baier2019,
  author     = {Baier, Lucas and Jöhren, Fabian and Seebacher, Stefan},
  booktitle  = {ECIS 2019 - 27th European Conference on Information Systems},
  title      = {Challenges in the deployment and operation of machine learning in practice},
  year       = {2019},
  month      = {05},
  abstract   = {Machine learning has recently emerged as a powerful technique to increase operational efficiency or to develop new value propositions. However, the translation of a prediction algorithm into an operationally usable machine learning model is a time-consuming and in various ways challenging task. In this work, we target to systematically elicit the challenges in deployment and operation to enable broader practical dissemination of machine learning applications. To this end, we first identify relevant challenges with a structured literature analysis. Subsequently, we conduct an interview study with machine learning practitioners across various industries, perform a qualitative content analysis, and identify challenges organized along three distinct categories as well as six overarching clusters. Eventually, results from both literature and interviews are evaluated with a comparative analysis. Key issues identified include automated strategies for data drift detection and handling, standardization of machine learning infrastructure, and appropriate communication and expectation management.},
  comment    = {Comprehensive "Related work"-section that is grouped by MLOps stages.},
  keywords   = {review, related},
  priority   = {prio1},
  readstatus = {skimmed},
  relevance  = {relevant},
  url        = {https://www.researchgate.net/publication/332996647_CHALLENGES_IN_THE_DEPLOYMENT_AND_OPERATION_OF_MACHINE_LEARNING_IN_PRACTICE},
}

@InProceedings{Maekinen2021,
  author        = {Sasu Mäkinen and Henrik Skogström and Eero Laaksonen and Tommi Mikkonen},
  title         = {Who Needs {MLOps}: What Data Scientists Seek to Accomplish and How Can {MLOps} Help?},
  year          = {2021},
  month         = mar,
  publisher     = {{IEEE}},
  abstract      = {Following continuous software engineering practices, there has been an increasing interest in rapid deployment of machine learning (ML) features, called MLOps. In this paper, we study the importance of MLOps in the context of data scientists' daily activities, based on a survey where we collected responses from 331 professionals from 63 different countries in ML domain, indicating on what they were working on in the last three months. Based on the results, up to 40\% respondents say that they work with both models and infrastructure; the majority of the work revolves around relational and time series data; and the largest categories of problems to be solved are predictive analysis, time series data, and computer vision. The biggest perceived problems revolve around data, although there is some awareness of problems related to deploying models to production and related procedures. To hypothesise, we believe that organisations represented in the survey can be divided to three categories -- (i) figuring out how to best use data; (ii) focusing on building the first models and getting them to production; and (iii) managing several models, their versions and training datasets, as well as retraining and frequent deployment of retrained models. In the results, the majority of respondents are in category (i) or (ii), focusing on data and models; however the benefits of MLOps only emerge in category (iii) when there is a need for frequent retraining and redeployment. Hence, setting up an MLOps pipeline is a natural step to take, when an organization takes the step from ML as a proof-of-concept to ML as a part of nominal activities.},
  archiveprefix = {arXiv},
  doi           = {10.1109/wain52551.2021.00024},
  eprint        = {2103.08942},
  file          = {:http\://arxiv.org/pdf/2103.08942v1:PDF},
  keywords      = {cs.SE, background},
  primaryclass  = {cs.SE},
}

@Article{Kumeno2020,
  author     = {Fumihiro Kumeno},
  journal    = {Intelligent Decision Technologies},
  title      = {Sofware engneering challenges for machine learning applications: A literature review},
  year       = {2020},
  issn       = {18724981, 18758843},
  pages      = {463-476},
  volume     = {13},
  abstract   = {Machine learning techniques, especially deep learning, have achieved remarkable breakthroughs over the past decade. At present, machine learning applications are deployed in many fields. However, the outcomes of software engineering researches are not always easily utilized in the development and deployment of machine learning applications. The main reason for this difficulty is the many differences between machine learning applications and traditional information systems. Machine learning techniques are evolving rapidly, but face inherent technical and non-technical challenges that complicate their lifecycle activities. This review paper attempts to clarify the software engineering challenges for machine learning applications that either exist or potentially exist by conducting a systematic literature collection and by mapping the identified challenge topics to knowledge areas defined by the Software Engineering Body of Knowledge (Swebok).},
  comment    = {SLR to outline the challenges in field of SE for ML applications, mapping the challenges encountered to the 12 knowledge areas of the Software Engineering Body of Knowledge (SWEBOK).

RQ1: What SE challenges for ML applications have been discussed and potentially exist?
RQ2: Which knowledge area is closely related to each of them?

Used snowballing because literature search did not produce adequate papers.

Describes the SE4ML challenges of each KA in SWEBOK.

108 papers mapped. 115 total. 2000-2019.
Two iterations of snowballing.},
  doi        = {10.3233/IDT-190160},
  keywords   = {related},
  priority   = {prio1},
  publisher  = {IOS Press},
  readstatus = {read},
  relevance  = {relevant},
}

@Article{Nascimento2020,
  author        = {Elizamary Nascimento and Anh Nguyen-Duc and Ingrid Sundbø and Tayana Conte},
  title         = {Software engineering for artificial intelligence and machine learning software: A systematic literature review},
  year          = {2020},
  month         = nov,
  abstract      = {Artificial Intelligence (AI) or Machine Learning (ML) systems have been widely adopted as value propositions by companies in all industries in order to create or extend the services and products they offer. However, developing AI/ML systems has presented several engineering problems that are different from those that arise in, non-AI/ML software development. This study aims to investigate how software engineering (SE) has been applied in the development of AI/ML systems and identify challenges and practices that are applicable and determine whether they meet the needs of professionals. Also, we assessed whether these SE practices apply to different contexts, and in which areas they may be applicable. We conducted a systematic review of literature from 1990 to 2019 to (i) understand and summarize the current state of the art in this field and (ii) analyze its limitations and open challenges that will drive future research. Our results show these systems are developed on a lab context or a large company and followed a research-driven development process. The main challenges faced by professionals are in areas of testing, AI software quality, and data management. The contribution types of most of the proposed SE practices are guidelines, lessons learned, and tools.},
  archiveprefix = {arXiv},
  comment       = {SLR of SE practices for ML.
Mapped practices to chapters of SWEBOK, similarly to Kumeno,  although with a more comprehensive analysis.  The authors found that studies from laboratory environments are mainly concerned with building and testing models, which could indicate that more literature produced by industry practitioners should be studied when looking to review the state of the art and state of practice of deploying models to production.  This is further illustrated when the authors highlight that deployment is one of the areas with the fewest suggested practices in published literature.

RQ: How is software engineering applied in the development of AI/ML systems?

RQ1. What types of AI/ML systems are investigated in the primary studies?  
RQ2. What is the organizational context of the AI/ML system development?  
RQ3. Which challenges are related to specific aspects of AI/ML development?  
RQ4. How  are  SE  practices  adjusted  to  deal  with  specific AI/ML  engineering challenges?  
RQ5. What SE practices are reported in the primary studies?   
RQ6. Which type of empirical methods are used?

Contributions: The  study  provides  a  comprehensive  view  of  the  software  industry  regarding  the development of AI/ML systems and lists the main challenges faced. 
II. The  study  synthesizes  the  contextual  setting  of  investigated  SE  practices,  and infers the area of applicability of the empirical findings., It also presents the classification of  SE  practice  types  in  the  form  of  lessons  learned,  structure,  guidelines,  theory,  tools, model, or advice. This can help to compare and generalize future research on SE practices for AI/ML systems.

Fails to mention the work of Kumeno, despite being submitted to arXiv 9 months later.

First uses DB search, then snowballing. 30+25 papers reviewed total.

Provides tables for "SE approaches, processes, practices, or tools reported", but only for areas for testing, configuration management, and design.

Looks at reported challenges vs proposed solutions. Many proposed solutions are not tested in industrial settings. Most proposed solutions are related to testing. 

Investigates settings in which the primary studies were conducted (research institution, small company, large company, etc)

More rigorous than Kumeno. Study performed by 3 researchers, coding process reviewed by two researchers.},
  eprint        = {2011.03751},
  file          = {:http\://arxiv.org/pdf/2011.03751v1:PDF},
  keywords      = {cs.SE, cs.AI, related},
  primaryclass  = {cs.SE},
  priority      = {prio2},
  readstatus    = {skimmed},
  relevance     = {relevant},
}

@Book{Bourque2014,
  author    = {Bourque, Pierre},
  publisher = {IEEE Computer Society},
  title     = {SWEBOK : guide to the software engineering body of knowledge},
  year      = {2014},
  address   = {Los Alamitos, CA},
  isbn      = {0769551661},
  keywords  = {background},
}

@Article{Lwakatare2020,
  author     = {Lucy Ellen Lwakatare and Aiswarya Raj and Ivica Crnkovic and Jan Bosch and Helena Holmström Olsson},
  journal    = {Information and Software Technology},
  title      = {Large-scale machine learning systems in real-world industrial settings: A review of challenges and solutions},
  year       = {2020},
  month      = {nov},
  pages      = {106368},
  volume     = {127},
  abstract   = {Background: Developing and maintaining large scale machine learning (ML) based software systems in an industrial setting is challenging. There are no well-established development guidelines, but the literature contains reports on how companies develop and maintain deployed ML-based software systems.

Objective: This study aims to survey the literature related to development and maintenance of large scale ML-based systems in industrial settings in order to provide a synthesis of the challenges that practitioners face. In addition, we identify solutions used to address some of these challenges.

Method: A systematic literature review was conducted and we identified 72 papers related to development and maintenance of large scale ML-based software systems in industrial settings. The selected articles were qualitatively analyzed by extracting challenges and solutions. The challenges and solutions were thematically synthesized into four quality attributes: adaptability, scalability, safety and privacy. The analysis was done in relation to ML workflow, i.e. data acquisition, training, evaluation, and deployment.

Results: We identified a total of 23 challenges and 8 solutions related to development and maintenance of large scale ML-based software systems in industrial settings including six different domains. Challenges were most often reported in relation to adaptability and scalability. Safety and privacy challenges had the least reported solutions.

Conclusion: The development and maintenance on large-scale ML-based systems in industrial settings introduce new challenges specific for ML, and for the known challenges characteristic for these types of systems, require new methods in overcoming the challenges. The identified challenges highlight important concerns in ML system development practice and the lack of solutions point to directions for future research.},
  comment    = {SLR on SE4ML using a two-dimensional approach, categorizing  challenges according to both  quality  attributes  (adaptability, scalability,privacy and safety) and ML development workflow step (data acquisition, training, evaluation, deployment).
The authors mentioned the exclusion of grey  literature (GL) as a potential weakness of their study.},
  doi        = {10.1016/j.infsof.2020.106368},
  keywords   = {related},
  priority   = {prio2},
  publisher  = {Elsevier {BV}},
  readstatus = {skimmed},
  relevance  = {relevant},
}

@InProceedings{Wohlin2014,
  author    = {Claes Wohlin},
  booktitle = {Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering - {EASE} {\textquotesingle}14},
  title     = {Guidelines for snowballing in systematic literature studies and a replication in software engineering},
  year      = {2014},
  publisher = {{ACM} Press},
  abstract  = {Background: Systematic literature studies have become common in software engineering, and hence it is important to understand how to conduct them efficiently and reliably.

Objective: This paper presents guidelines for conducting literature reviews using a snowballing approach, and they are illustrated and evaluated by replicating a published systematic literature review.

Method: The guidelines are based on the experience from conducting several systematic literature reviews and experimenting with different approaches.

Results: The guidelines for using snowballing as a way to search for relevant literature was successfully applied to a systematic literature review.

Conclusions: It is concluded that using snowballing, as a first search strategy, may very well be a good alternative to the use of database searches.},
  doi       = {10.1145/2601248.2601268},
  keywords  = {guidelines},
}

@InProceedings{Garousi2016,
  author    = {Vahid Garousi and Michael Felderer and Mika V. Mäntylä},
  booktitle = {Proceedings of the 20th International Conference on Evaluation and Assessment in Software Engineering},
  title     = {The need for multivocal literature reviews in software engineering},
  year      = {2016},
  month     = {jun},
  publisher = {{ACM}},
  abstract  = {Systematic Literature Reviews (SLR) may not provide insight into the "state of the practice" in SE, as they do not typically include the "grey" (non-published) literature. A Multivocal Literature Review (MLR) is a form of a SLR which includes grey literature in addition to the published (formal) literature. Only a few MLRs have been published in SE so far. We aim at raising the awareness for MLRs in SE by addressing two research questions (RQs): (1) What types of knowledge are missed when a SLR does not include the multivocal literature in a SE field? and (2) What do we, as a community, gain when we include the multivocal literature and conduct MLRs? To answer these RQs, we sample a few example SLRs and MLRs and identify the missing and the gained knowledge due to excluding or including the grey literature. We find that (1) grey literature can give substantial benefits in certain areas of SE, and that (2) the inclusion of grey literature brings forward certain challenges as evidence in them is often experience and opinion based. Given these conflicting viewpoints, the authors are planning to prepare systematic guidelines for performing MLRs in SE.},
  doi       = {10.1145/2915970.2916008},
}

@InCollection{Lwakatare2020a,
  author     = {Lucy Ellen Lwakatare and Ivica Crnkovic and Ellinor R{\aa}nge and Jan Bosch},
  booktitle  = {Product-Focused Software Process Improvement},
  publisher  = {Springer International Publishing},
  title      = {From a Data Science Driven Process to a Continuous Delivery Process for Machine Learning Systems},
  year       = {2020},
  pages      = {185--201},
  abstract   = {Development of machine learning (ML) enabled applications in real-world settings is challenging and requires the consideration of sound software engineering (SE) principles and practices. A large body of knowledge exists on the use of modern approaches to developing traditional software components, but not ML components. Using exploratory case study approach, this study investigates the adoption and use of existing software development approaches, specifically continuous delivery (CD), to development of ML components. Research data was collected using a multivocal literature review (MLR) and focus group technique with ten practitioners involved in developing ML-enabled systems at a large telecommunication company. The results of our MLR show that companies do not outright apply CD to the development of ML components rather as a result of improving their development practices and infrastructure over time. A process improvement conceptual model, that includes the description of CD application to ML components is developed and initially validated in the study.},
  doi        = {10.1007/978-3-030-64148-1_12},
  keywords   = {literature review, related},
  priority   = {prio1},
  ranking    = {rank3},
  readstatus = {skimmed},
  relevance  = {relevant},
}

@InProceedings{Serban2020,
  author     = {Alex Serban and Koen van der Blom and Holger Hoos and Joost Visser},
  booktitle  = {Proceedings of the 14th {ACM} / {IEEE} International Symposium on Empirical Software Engineering and Measurement ({ESEM})},
  title      = {Adoption and Effects of Software Engineering Best Practices in Machine Learning},
  year       = {2020},
  month      = {oct},
  publisher  = {{ACM}},
  abstract   = {Background. The increasing reliance on applications with machine learning (ML) components calls for mature engineering techniques that ensure these are built in a robust and future-proof manner.

Aim. We aim to empirically determine the state of the art in how teams develop, deploy and maintain software with ML components.

Method. We mined both academic and grey literature and identified 29 engineering best practices for ML applications. We conducted a survey among 313 practitioners to determine the degree of adoption for these practices and to validate their perceived effects. Using the survey responses, we quantified practice adoption, differentiated along demographic characteristics, such as geography or team size. We also tested correlations and investigated linear and non-linear relationships between practices and their perceived effect using various statistical models.

Results. Our findings indicate, for example, that larger teams tend to adopt more practices, and that traditional software engineering practices tend to have lower adoption than ML specific practices. Also, the statistical models can accurately predict perceived effects such as agility, software quality and traceability, from the degree of adoption for specific sets of practices. Combining practice adoption rates with practice importance, as revealed by statistical models, we identify practices that are important but have low adoption, as well as practices that are widely adopted but are less important for the effects we studied.

Conclusion. Overall, our survey and the analysis of responses received provide a quantitative basis for assessment and step-wise improvement of practice adoption by ML teams.},
  comment    = {MLR + questionnaire
- MLR investigates best SE practices for ML
- questionnaire for practitioners at different types of institutions with quantitative analysis
- analyzes which practices identified in MLR are actually adopted and relationship with other variables},
  doi        = {10.1145/3382494.3410681},
  keywords   = {background, related},
  priority   = {prio1},
  readstatus = {skimmed},
  relevance  = {relevant},
}

@InCollection{Lwakatare2019,
  author     = {Lucy Ellen Lwakatare and Aiswarya Raj and Jan Bosch and Helena Holmström Olsson and Ivica Crnkovic},
  booktitle  = {Lecture Notes in Business Information Processing},
  publisher  = {Springer International Publishing},
  title      = {A Taxonomy of Software Engineering Challenges for Machine Learning Systems: An Empirical Investigation},
  year       = {2019},
  pages      = {227--243},
  abstract   = {Artificial intelligence enabled systems have been an inevitable part of everyday life. However, efficient software engineering principles and processes need to be considered and extended when developing AI- enabled systems. The objective of this study is to identify and classify software engineering challenges that are faced by different companies when developing software-intensive systems that incorporate machine learning components. Using case study approach, we explored the development of machine learning systems from six different companies across various domains and identified main software engineering challenges. The challenges are mapped into a proposed taxonomy that depicts the evolution of use of ML components in software-intensive system in industrial settings. Our study provides insights to software engineering community and research to guide discussions and future research into applied machine learning.},
  doi        = {10.1007/978-3-030-19034-7_14},
  keywords   = {background},
  priority   = {prio3},
  readstatus = {skimmed},
}

@InProceedings{Washizaki2019,
  author    = {Hironori Washizaki and Hiromu Uchida and Foutse Khomh and Yann-Gael Gueheneuc},
  booktitle = {2019 10th International Workshop on Empirical Software Engineering in Practice ({IWESEP})},
  title     = {Studying Software Engineering Patterns for Designing Machine Learning Systems},
  year      = {2019},
  month     = {dec},
  publisher = {{IEEE}},
  abstract  = {Machine-learning (ML) techniques are becoming more prevalent. ML techniques rely on mathematics and software engineering. Researchers and practitioners studying best practices strive to design ML systems and software that address software complexity and quality issues. Such design practices are often formalized as architecture and design patterns by encapsulating reusable solutions to common problems within given contexts. However, a systematic study to collect, classify, and discuss these software-engineering (SE) design patterns for ML techniques have yet to be reported. Our research collects good/bad SE design patterns for ML techniques to provide developers with a comprehensive classification of such patterns. Herein we report the preliminary results of a systematic-literature review (SLR) of good/bad design patterns for ML.},
  doi       = {10.1109/iwesep49350.2019.00017},
  priority  = {prio3},
}

@Article{Karamitsos2020,
  author     = {Ioannis Karamitsos and Saeed Albarhami and Charalampos Apostolopoulos},
  journal    = {Information},
  title      = {Applying {DevOps} Practices of Continuous Automation for Machine Learning},
  year       = {2020},
  issn       = {2078-2489},
  month      = {jul},
  number     = {7},
  pages      = {363},
  volume     = {11},
  abstract   = {This paper proposes DevOps practices for machine learning application, integrating both the development and operation environment seamlessly. The machine learning processes of development and deployment during the experimentation phase may seem easy. However, if not carefully designed, deploying and using such models may lead to a complex, time-consuming approaches which may require significant and costly efforts for maintenance, improvement, and monitoring. This paper presents how to apply continuous integration (CI) and continuous delivery (CD) principles, practices, and tools so as to minimize waste, support rapid feedback loops, explore the hidden technical debt, improve value delivery and maintenance, and improve operational functions for real-world machine learning applications.},
  doi        = {10.3390/info11070363},
  keywords   = {systematic literature review, related},
  priority   = {prio2},
  publisher  = {{MDPI} {AG}},
  ranking    = {rank5},
  readstatus = {skimmed},
}

@Article{Lorenzoni2021,
  author        = {Giuliano Lorenzoni and Paulo Alencar and Nathalia Nascimento and Donald Cowan},
  title         = {Machine Learning Model Development from a Software Engineering Perspective: A Systematic Literature Review},
  year          = {2021},
  month         = feb,
  abstract      = {Data scientists often develop machine learning models to solve a variety of problems in the industry and academy but not without facing several challenges in terms of Model Development. The problems regarding Machine Learning Development involves the fact that such professionals do not realize that they usually perform ad-hoc practices that could be improved by the adoption of activities presented in the Software Engineering Development Lifecycle. Of course, since machine learning systems are different from traditional Software systems, some differences in their respective development processes are to be expected. In this context, this paper is an effort to investigate the challenges and practices that emerge during the development of ML models from the software engineering perspective by focusing on understanding how software developers could benefit from applying or adapting the traditional software engineering process to the Machine Learning workflow.},
  archiveprefix = {arXiv},
  eprint        = {2102.07574},
  file          = {:http\://arxiv.org/pdf/2102.07574v1:PDF},
  keywords      = {cs.SE, cs.AI, cs.LG, related},
  primaryclass  = {cs.SE},
  priority      = {prio3},
}

@Article{MartinezFernandez2021,
  author        = {Silverio Mart{\'{i}}nez-Fern{\'{a}}ndez and Justus Bogner and Xavier Franch and Marc Oriol and Julien Siebert and Adam Trendowicz and Anna Maria Vollmer and Stefan Wagner},
  title         = {Software Engineering for AI-Based Systems: A Survey},
  year          = {2021},
  month         = may,
  abstract      = {AI-based systems are software systems with functionalities enabled by at least one AI component (e.g., for image- and speech-recognition, and autonomous driving). AI-based systems are becoming pervasive in society due to advances in AI. However, there is limited synthesized knowledge on Software Engineering (SE) approaches for building, operating, and maintaining AI-based systems. To collect and analyze state-of-the-art knowledge about SE for AI-based systems, we conducted a systematic mapping study. We considered 248 studies published between January 2010 and March 2020. SE for AI-based systems is an emerging research area, where more than 2/3 of the studies have been published since 2018. The most studied properties of AI-based systems are dependability and safety. We identified multiple SE approaches for AI-based systems, which we classified according to the SWEBOK areas. Studies related to software testing and software quality are very prevalent, while areas like software maintenance seem neglected. Data-related issues are the most recurrent challenges. Our results are valuable for: researchers, to quickly understand the state of the art and learn which topics need more research; practitioners, to learn about the approaches and challenges that SE entails for AI-based systems; and, educators, to bridge the gap among SE and AI in their curricula.},
  archiveprefix = {arXiv},
  comment       = {Extensive systematic mapping study of SE for AI.
- RQ1. How is SE research for AI-based systems characterized?
- RQ2. What are the characteristics of AI-based systems (used terms, scope, and quality goals)?
- RQ3. Which SE approaches for AI-based systems have been reported in the scientific literature?
- RQ4. What are the existing challenges associated with SE for AI-based systems?

Maps SE4AI approaches to SWEBOK KAs.
Maps challenges in approaches to SWEBOK KAs.},
  eprint        = {2105.01984},
  file          = {:http\://arxiv.org/pdf/2105.01984v2:PDF},
  keywords      = {cs.SE, cs.AI, cs.LG, D.2; I.2, systematic mapping study, related},
  primaryclass  = {cs.SE},
  priority      = {prio1},
  ranking       = {rank5},
  readstatus    = {skimmed},
  relevance     = {relevant},
}

@Report{algorithmia2020,
  keywords     = {background},
  organization = {Algorithmia, Inc.},
  title        = {2021 enterprise trends in machine learning},
  url          = {https://info.algorithmia.com/2021},
  year         = {2020},
}

@Report{mckinsey2020,
  keywords     = {background},
  organization = {McKinsey & Company},
  title        = {The state of {AI} in 2020},
  url          = {https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/global-survey-the-state-of-ai-in-2020},
  year         = {2020},
}

@Article{Serban2021,
  author        = {Alex Serban and Joost Visser},
  title         = {An Empirical Study of Software Architecture for Machine Learning},
  year          = {2021},
  month         = may,
  abstract      = {Specific developmental and operational characteristics of machine learning (ML) components, as well as their inherent uncertainty, demand robust engineering principles are used to ensure their quality. We aim to determine how software systems can be (re-) architected to enable robust integration of ML components. Towards this goal, we conducted a mixed-methods empirical study consisting of (i) a systematic literature review to identify the challenges and their solutions in software architecture forML, (ii) semi-structured interviews with practitioners to qualitatively complement the initial findings, and (iii) a survey to quantitatively validate the challenges and their solutions. In total, we compiled and validated twenty challenges and solutions for (re-) architecting systems with ML components. Our results indicate, for example, that traditional software architecture challenges (e.g., component coupling) also play an important role when using ML components; along new ML specific challenges (e.g., the need for continuous retraining). Moreover, the results indicate that ML heightened decision drivers, such as privacy, play a marginal role compared to traditional decision drivers, such as scalability or interoperability. Using the survey, we were able to establish a link between architectural solutions and software quality attributes; which enabled us to provide twenty architectural tactics used for satisfying individual quality requirements of systems with ML components. Altogether, the results can be interpreted as an empirical framework that supports the process of (re-) architecting software systems with ML components.},
  archiveprefix = {arXiv},
  comment       = {Low priority, not published.},
  eprint        = {2105.12422},
  file          = {:http\://arxiv.org/pdf/2105.12422v1:PDF},
  keywords      = {cs.SE, systematic literature review, related},
  primaryclass  = {cs.SE},
  priority      = {prio3},
}

@InCollection{Schloegl2019,
  author    = {Stephan Schlögl and Claudia Postulka and Reinhard Bernsteiner and Christian Ploder},
  publisher = {Springer International Publishing},
  title     = {Artificial Intelligence Tool Penetration in Business: Adoption, Challenges and Fears},
  year      = {2019},
  pages     = {259--270},
  abstract  = {Artificial Intelligence (AI) and its promise to improve the efficiency of entire business value chains has been headlining newspapers for the last years. However, it seems that many companies struggle in finding the right tools and use cases for their distinct fields of application. Thus, the aim of the presented study was to evaluate the current state of machine learning and co in various European companies. Talking to 19 employees from various different industry sectors, we explored applicability of AI tools as well as human attitudes towards these technologies. Results show that AI implementations are still in their early stages, with a rather small number of viable use cases. Tools are predominantly bespoke and internally built, while off-the-shelf solutions suffer from a lack of trust in third party service providers. Although companies claim to have no intention of reducing the workforce in favor of AI technology, employees fear job loss and thus often reject adoption. Another important challenge concerns data privacy and ethics, which has grown in relevance with respect to recent changes in European legislation. In summary, we found that companies recognize the competitive advantage AI may attribute to their value chains, in particular when it comes to automation and increased process efficiency. Yet they are also aware of the rather social challenges, which currently inhibit the proliferation of AI-driven solutions.},
  comment   = {AI adoption is still in a very early stage.

"Results show that the majority of companies are still at the very starting point when it comes to the implementation of respective solutions},
  doi       = {10.1007/978-3-030-21451-7_22},
  keywords  = {background},
}

@TechReport{itu2018,
  author      = {Unknown},
  institution = {International Telecommunication Union},
  title       = {Assessing the {Economic} {Impact} of {Artificial} {Intelligence}},
  year        = {2018},
  month       = sep,
  doi         = {https://doi.org/11.1002/pub/81202956-en},
  keywords    = {background},
  url         = {http://handle.itu.int/11.1002/pub/81202956-en},
}

@Article{Kiraly2021,
  author        = {Franz J. Király and Markus Löning and Anthony Blaom and Ahmed Guecioueur and Raphael Sonabend},
  title         = {Designing Machine Learning Toolboxes: Concepts, Principles and Patterns},
  year          = {2021},
  month         = jan,
  abstract      = {Machine learning (ML) and AI toolboxes such as scikit-learn or Weka are workhorses of contemporary data scientific practice -- their central role being enabled by usable yet powerful designs that allow to easily specify, train and validate complex modeling pipelines. However, despite their universal success, the key design principles in their construction have never been fully analyzed. In this paper, we attempt to provide an overview of key patterns in the design of AI modeling toolboxes, taking inspiration, in equal parts, from the field of software engineering, implementation patterns found in contemporary toolboxes, and our own experience from developing ML toolboxes. In particular, we develop a conceptual model for the AI/ML domain, with a new type system, called scientific types, at its core. Scientific types capture the scientific meaning of common elements in ML workflows based on the set of operations that we usually perform with them (i.e. their interface) and their statistical properties. From our conceptual analysis, we derive a set of design principles and patterns. We illustrate that our analysis can not only explain the design of existing toolboxes, but also guide the development of new ones. We intend our contribution to be a state-of-art reference for future toolbox engineers, a summary of best practices, a collection of ML design patterns which may become useful for future research, and, potentially, the first steps towards a higher-level programming paradigm for constructing AI.},
  archiveprefix = {arXiv},
  eprint        = {2101.04938},
  file          = {:http\://arxiv.org/pdf/2101.04938v1:PDF},
  keywords      = {cs.SE, cs.LG},
  primaryclass  = {cs.SE},
}

@Article{Shahin2017,
  author    = {Mojtaba Shahin and Muhammad Ali Babar and Liming Zhu},
  journal   = {IEEE Access},
  title     = {Continuous Integration, Delivery and Deployment: A Systematic Review on Approaches, Tools, Challenges and Practices},
  year      = {2017},
  pages     = {3909--3943},
  volume    = {5},
  abstract  = {Continuous practices, i.e., continuous integration, delivery, and deployment, are the software development industry practices that enable organizations to frequently and reliably release new features and products. With the increasing interest in the literature on continuous practices, it is important to systematically review and synthesize the approaches, tools, challenges, and practices reported for adopting and implementing continuous practices. This paper aimed at systematically reviewing the state of the art of continuous practices to classify approaches and tools, identify challenges and practices in this regard, and identify the gaps for future research. We used the systematic literature review method for reviewing the peer-reviewed papers on continuous practices published between 2004 and June 1, 2016. We applied the thematic analysis method for analyzing the data extracted from reviewing 69 papers selected using predefined criteria. We have identified 30 approaches and associated tools, which facilitate the implementation of continuous practices in the following ways: (1) reducing build and test time in continuous integration (CI); (2) increasing visibility and awareness on build and test results in CI; (3) supporting (semi-) automated continuous testing; (4) detecting violations, flaws, and faults in CI; (5) addressing security and scalability issues in deployment pipeline; and (6) improving dependability and reliability of deployment process. We have also determined a list of critical factors, such as testing (effort and time), team awareness and transparency, good design principles, customer, highly skilled and motivated team, application domain, and appropriate infrastructure that should be carefully considered when introducing continuous practices in a given organization. The majority of the reviewed papers were validation (34.7\%) and evaluation (36.2\%) research types. This paper also reveals that continuous practices have been successfully applied to both greenfield and maintenance projects. Continuous practices have become an important area of software engineering research and practice. While the reported approaches, tools, and practices are addressing a wide range of challenges, there are several challenges and gaps, which require future research work for improving the capturing and reporting of contextual information in the studies reporting different aspects of continuous practices; gaining a deep understanding of how software-intensive systems should be (re-) architected to support continuous practices; and addressing the lack of knowledge and tools for engineering processes of designing and running secure deployment pipelines.},
  comment   = {SLR of CI/CD and deployment.
Focus on tools, practices, challenges and approaches for continuous software engineering.
69 studies reviewed.},
  doi       = {10.1109/access.2017.2685629},
  keywords  = {background, related},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  relevance = {relevant},
}

@Article{Rodriguez2017,
  author    = {Pilar Rodr{\'{i}}guez and Alireza Haghighatkhah and Lucy Ellen Lwakatare and Susanna Teppola and Tanja Suomalainen and Juho Eskeli and Teemu Karvonen and Pasi Kuvaja and June M. Verner and Markku Oivo},
  journal   = {Journal of Systems and Software},
  title     = {Continuous deployment of software intensive products and services: A systematic mapping study},
  year      = {2017},
  month     = {jan},
  pages     = {263--291},
  volume    = {123},
  abstract  = {The software intensive industry is moving towards the adoption of a value-driven and adaptive real-time business paradigm. The traditional view of software as an item that evolves through releases every few months is being replaced by the continuous evolution of software functionality. This study aims to classify and analyse the literature related to continuous deployment in the software domain in order to scope the phenomenon, provide an overview of the state-of-the-art, investigate the scientific evidence in the reported results and identify areas suitable for further research. We conducted a systematic mapping study and classified the continuous deployment literature. The benefits and challenges related to continuous deployment were also analysed. RESULTS: The systematic mapping study includes 50 primary studies published between 2001 and 2014. An in-depth analysis of the primary studies revealed ten recurrent themes that characterize continuous deployment and provide researchers with directions for future work. In addition, a set of benefits and challenges of which practitioners may take advantage were identified. CONCLUSION: Overall, although the topic area is very promising, it is still in its infancy, thus offering a plethora of new opportunities for both researchers and software intensive companies.},
  comment   = {Goals:
1. To establish the body of knowledge of CD by identifying and categorizing the available research on the topic
2. To assess the quality of the existing research in terms of industrial relevance and research rigour
3. To identify the most relevant articles in the field of CD
4. To determine the underlying factors that characterize CD as both a concept and a phenomenon
5. To provide baselines to assist with further research},
  doi       = {10.1016/j.jss.2015.12.015},
  keywords  = {background, related},
  publisher = {Elsevier {BV}},
  relevance = {relevant},
}

@Article{Ebert2016,
  author    = {Christof Ebert and Gorka Gallardo and Josune Hernantes and Nicolas Serrano},
  title     = {{DevOps}},
  year      = {2016},
  month     = {may},
  number    = {3},
  pages     = {94--100},
  volume    = {33},
  abstract  = {Building on lean and agile practices, DevOps means end-to-end automation in software development and delivery. Hardly anybody will be able to approach it with a cookbook-style approach, but most developers will benefit from better connecting the previously isolated silos of development and operations. Many DevOps tools exist that can help them do this.},
  doi       = {10.1109/ms.2016.68},
  keywords  = {background},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@InProceedings{Franca2016,
  author    = {Breno B. Nicolau de Fran{\c{c}}a and Helvio Jeronimo and Guilherme Horta Travassos},
  title     = {Characterizing {DevOps} by Hearing Multiple Voices},
  year      = {2016},
  publisher = {{ACM} Press},
  abstract  = {Recently, DevOps has emerged as an alternative for software organizations inserted into a dynamic market to handle daily software demands. As claimed, it intends to make the software development and operations teams to work collaboratively. However, it is hard to observe a shared understanding of DevOps, what potentially hinders the discussions in the literature and can confound observations when conducting empirical studies. Therefore, we performed a Multivocal Literature Review aiming at characterizing DevOps in multiple perspectives, including data sources from technical and gray literature. Grounded Theory procedures were used to rigorous analyze the collected data. It allowed us to achieve a grounded definition for DevOps, as well as to identify its recurrent principles, practices, required skills, potential benefits, challenges and what motivates the organizations to adopt it. Finally, we understand the DevOps movement has identified relevant issues in the state-of-the-practice. However, we advocate for the scientific investigations concerning the potential benefits and drawbacks as a consequence of adopting the suggested principles and practices.},
  comment   = {answers "what is devops?"
specifically mentions automation as one of the core principles of devops
infrastructure consistency
repeatability

also identifies practices. good for devops background.

"DevOps  aims  at  constantly  and  rapidly  delivering valuable software, requiring automation to support activities such as build, deploy to production-like environments, testing at different levels and so on. However, one of the challenges  for the implementation  of  DevOps  is  the  lack  of  adequate  infrastructure to support the automation of these tasks [2]. Moreover, not having infrastructure  provisioning  in  an  automated  procedure  represents an obstacle. The ability to keep operations stable is also identified as a challenge hindering the adoption of DevOps."},
  doi       = {10.1145/2973839.2973845},
  keywords  = {background},
}

@InProceedings{John2021a,
  author     = {Meenu Mary John and Helena Holmstrom Olsson and Jan Bosch},
  title      = {Towards {MLOps}: A Framework and Maturity Model},
  year       = {2021},
  month      = {sep},
  publisher  = {{IEEE}},
  comment    = {- RQ1: What is the state-of-the-art regarding the adoption of MLOps in practice and the different stages that companies go through in evolving their MLOps practices?
- RQ2: How do case companies evolve and advance their MLOps practices?

Performs SLR and GLR to answer RQs.
Gives a high-level description of MLOps practices based on SLR and GLR.
Develops a maturity framework which outlines four stages that companies move through as they adopt MLOps practices.
Performs case studies at three companies to validate the framework.

Maturity framework allows for characterization MLOps maturity at a company, but does not provide knowledge on how to actually deploy, explore the more nuanced aspects of deployment, etc.},
  doi        = {10.1109/seaa53835.2021.00050},
  keywords   = {related},
  priority   = {prio1},
  readstatus = {read},
}

@InProceedings{Philipp2020,
  author    = {Robert Philipp and Andreas Mladenow and Christine Strauss and Alexander Völz},
  title     = {Machine Learning as a Service},
  year      = {2020},
  month     = {nov},
  publisher = {{ACM}},
  doi       = {10.1145/3428757.3429152},
  keywords  = {related},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 KeywordGroup:Background information\;0\;keywords\;background\;0\;0\;1\;0xff00ffff\;\;\;;
1 KeywordGroup:Guidelines\;0\;keywords\;guidelines\;0\;0\;1\;0x8a8a8aff\;\;\;;
1 KeywordGroup:Related work\;0\;keywords\;related\;0\;0\;1\;0xcc3333ff\;\;\;;
}
