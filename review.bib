% Encoding: UTF-8

@InProceedings{Haldar2019,
  author    = {Malay Haldar and Mustafa Abdool and Prashant Ramanathan and Tao Xu and Shulin Yang and Huizhong Duan and Qing Zhang and Nick Barrow-Williams and Bradley C. Turnbull and Brendan M. Collins and Thomas Legrand},
  title     = {Applying Deep Learning to Airbnb Search},
  year      = {2019},
  month     = {jul},
  publisher = {{ACM}},
  comment   = {- “Towards the beginning of 2017 when we started shipping the TensorFlow models to production, we found no efficient solution to score the models within a Java stack. Typically a back and forth conversion of the data between Java and another language was required and the latency introduced in the process was a blocker for us.”
- Interoperation of Java, Scala, Tensorflow, Spark, Thrift, AWS},
  doi       = {10.1145/3292500.3330658},
  groups    = {Start set},
}

@InCollection{Bosch2021,
  author    = {Jan Bosch and Helena Holmström Olsson and Ivica Crnkovic},
  publisher = {{IGI} Global},
  title     = {Engineering {AI} Systems},
  year      = {2021},
  pages     = {1--19},
  comment   = {- deployment is highly underestimated area. companies struggle with: monitoring, logging, testing, troubleshooting, resource limitations, significant amounts of glue code
Primary research challenges identified:
- federated learning infrastructure: solutions are needed for federated learning and the sharing of model parameters such as neural network weights as well as selected data sets that, for instance, represent cases not well handled by the central model. Federated learning requires an infrastructure to achieve the required quality attributes and to efficiently and securely share models and data.
- storage and computing infrastructure: many companies use internal infrastructure instead of cloud services. can be because of legal constraints, costs or quality attributes.
- deployment infrastructure: it is important for a deployment infrastructure to reliably deploy subsequent versions of models, measure their performance, raise warnings and initiate rollbacks in the case of anomalous behaviour.},
  doi       = {10.4018/978-1-7998-5101-1.ch001},
  groups    = {Start set, Selected from start set},
  relevance = {relevant},
}

@InProceedings{Hummer2019,
  author    = {Waldemar Hummer and Vinod Muthusamy and Thomas Rausch and Parijat Dube and Kaoutar El Maghraoui and Anupama Murthi and Punleuk Oum},
  title     = {{ModelOps}: Cloud-Based Lifecycle Management for Reliable and Trusted {AI}},
  year      = {2019},
  month     = {jun},
  publisher = {{IEEE}},
  comment   = {“systematic lifecycle support-including continuous development, training, testing, and deployment of models-and continuous integration [2] for AI is still in its infancy. We think one reason for this is the lack of tools and methodologies to support the development lifecycles of AI solutions, spanning data preparation, model design and training, application development, quality checks (e.g., security, bias, compliance, etc.), deployment, monitoring, and feedback, as well as the reproducibility and auditability of the entire process.”
- pluggability: “Lifecycle services must be easily pluggable and customizable, e.g. bias or robustness checks. some AI pipelines still require human in the loop.”
- reusability: keep config effort to a minimum. users should be able to use pre-configured templates and patterns for pipelines and lifecycle capabilities.
- flexibility: The system needs to meet developers and data scientists where they are, and integrate with the tools and services they already use and are comfortable with.
- scalability: The system needs to provide scalability across different dimensions - including model metadata versioning, parallel pipeline executions, event processing, and model performance monitoring.
- hybrid environments: While there is a general move to the cloud, a significant number of AI systems use on-premise servers, dedicated clusters, edge devices, or a combination of these. Resource and security heterogeneity in such hybrid environments introduce a number of challenges.
- fault tolerance: As ModelOps pipelines plug together a wide range of tools and infrastructure, many things can fail. For example, we found that 8% of all data preprocessing tasks in WML fail or finish with errors, and therefore would stall the subsequent training of a model. This is particularly problematic for automated pipelines of critical models.},
  doi       = {10.1109/ic2e.2019.00025},
  groups    = {Start set, Selected from start set},
  relevance = {relevant},
}

@InProceedings{Liu2017,
  author    = {David C. Liu and Stephanie Rogers and Raymond Shiau and Dmitry Kislyuk and Kevin C. Ma and Zhigang Zhong and Jenny Liu and Yushi Jing},
  title     = {Related Pins at Pinterest},
  year      = {2017},
  publisher = {{ACM} Press},
  comment   = {multiple different models/components that depend on eachother, meaning that changing a model requires that the whole system is retrained. 
"We identify unique interdependencies that made it hard to reason about changes in Related Pins, and propose to mitigate these issues by automated joint training of system components."

Improvements to raw data can harm results: “Currently we must manually retrain our model with updated raw data, and deploy the new model and raw data into production at the same time. In addition to being time consuming, this solution is less-than-ideal since it requires us to know of the upstream change. Ideally, we would automate the continual retraining of our model, which would incorporate any change in upstream data.”},
  doi       = {10.1145/3041021.3054202},
  groups    = {Start set},
}

@InCollection{MartinezFernandez2021,
  author    = {Silverio Mart{\'{\i}}nez-Fern{\'{a}}ndez and Xavier Franch and Andreas Jedlitschka and Marc Oriol and Adam Trendowicz},
  publisher = {Springer International Publishing},
  title     = {Developing and Operating Artificial Intelligence Models in Trustworthy Autonomous Systems},
  year      = {2021},
  pages     = {221--229},
  comment   = {“However, solutions or frameworks supporting the management of multiple instances of AI models deployed in different context-aware environments are scarce. Context is the missing piece in the AI lifecycle [15].”
“AI models are usually deployed as part of embedded systems, which require additional techniques for continuous deployment, such as Over-the-Air updates [18]. However, as aforementioned, none of the these approaches have a focus on trustworthiness nor context-specific AI model deployment.”
Proposed research direction: “Providing Intelligent and Context-Aware Techniques to Deploy Updated AI Models in AS (Autonomous Systems) Instances”

“Bringing Together the Development and Operation of AI Models in Trustworthy AS into a Holistic Lifecycle with Tool Support.”
“This direction includes the development of AI-specific, independent, and loosely coupled software components (ready to be integrated into companies’ development and operational environments) for the three directions we presented above.”

Proposes a holistic DevOps approach for AI in AS.},
  doi       = {10.1007/978-3-030-75018-3_14},
  groups    = {Start set},
}

@InProceedings{Karlas2020,
  author    = {Bojan Karla{\v{s}} and Matteo Interlandi and Cedric Renggli and Wentao Wu and Ce Zhang and Deepak Mukunthu Iyappan Babu and Jordan Edwards and Chris Lauren and Andy Xu and Markus Weimer},
  booktitle = {Proceedings of the 26th {ACM} {SIGKDD} International Conference on Knowledge Discovery {\&} Data Mining},
  title     = {Building Continuous Integration Services for Machine Learning},
  year      = {2020},
  month     = {jul},
  publisher = {{ACM}},
  doi       = {10.1145/3394486.3403290},
  groups    = {Start set},
}

@Article{Mariani2021,
  author    = {Stefano Mariani and Maarten M. H. Lahr and Esther Metting and Eloisa Vargiu and Franco Zambonelli},
  journal   = {International Journal of Intelligent Systems},
  title     = {Developing an {ML} pipeline for asthma and {COPD}: The case of a Dutch primary care service},
  year      = {2021},
  month     = {jul},
  doi       = {10.1002/int.22568},
  groups    = {Start set},
  publisher = {Wiley},
}

@Article{Ruf2021,
  author    = {Philipp Ruf and Manav Madan and Christoph Reich and Djaffar Ould-Abdeslam},
  title     = {Demystifying {MLOps} and Presenting a Recipe for the Selection of Open-Source Tools},
  year      = {2021},
  month     = {sep},
  number    = {19},
  pages     = {8861},
  volume    = {11},
  doi       = {10.3390/app11198861},
  groups    = {Start set, Selected from start set},
  publisher = {{MDPI} {AG}},
  relevance = {relevant},
}

@InCollection{Heuvel2020,
  author    = {Willem-Jan van den Heuvel and Damian A. Tamburri},
  publisher = {Springer International Publishing},
  title     = {Model-Driven {ML}-Ops for Intelligent Enterprise Applications: Vision, Approaches and Challenges},
  year      = {2020},
  pages     = {169--181},
  doi       = {10.1007/978-3-030-52306-0_11},
  groups    = {Start set},
}

@InProceedings{Zhou2020,
  author    = {Yue Zhou and Yue Yu and Bo Ding},
  title     = {Towards {MLOps}: A Case Study of {ML} Pipeline Platform},
  year      = {2020},
  month     = {oct},
  publisher = {{IEEE}},
  doi       = {10.1109/icaice51518.2020.00102},
  groups    = {Start set},
  relevance = {relevant},
}

@InProceedings{Tamburri2020,
  author    = {Damian A. Tamburri},
  title     = {Sustainable {MLOps}: Trends and Challenges},
  year      = {2020},
  month     = {sep},
  publisher = {{IEEE}},
  doi       = {10.1109/synasc51798.2020.00015},
  groups    = {Start set},
}

@Article{Granlund2021,
  author    = {Tuomas Granlund and Vlad Stirbu and Tommi Mikkonen},
  title     = {Towards Regulatory-Compliant {MLOps}: Oravizio's Journey from a Machine Learning Experiment to a Deployed Certified Medical Product},
  year      = {2021},
  month     = {jun},
  number    = {5},
  volume    = {2},
  doi       = {10.1007/s42979-021-00726-1},
  groups    = {Start set, Selected from start set},
  publisher = {Springer Science and Business Media {LLC}},
  relevance = {relevant},
}

@Article{Liu2020,
  author    = {Yan Liu and Zhijing Ling and Boyu Huo and Boqian Wang and Tianen Chen and Esma Mouine},
  title     = {Building A Platform for Machine Learning Operations from Open Source Frameworks},
  year      = {2020},
  number    = {5},
  pages     = {704--709},
  volume    = {53},
  doi       = {10.1016/j.ifacol.2021.04.161},
  groups    = {Start set, Selected from start set},
  publisher = {Elsevier {BV}},
  relevance = {relevant},
}

@Article{Ciucu2019,
  author    = {R. Ciucu and F.C. Adochiei and Ioana-Raluca Adochiei and F. Argatu and G.C. Seri{\c{t}}an and B. Enache and S. Grigorescu and Violeta Vasilica Argatu},
  title     = {Innovative Devops for Artificial Intelligence},
  year      = {2019},
  month     = {apr},
  number    = {1},
  pages     = {58--63},
  volume    = {19},
  doi       = {10.1515/sbeef-2019-0011},
  groups    = {Start set},
  publisher = {Walter de Gruyter {GmbH}},
  relevance = {relevant},
}

@InProceedings{Krishnamurthi2019,
  author    = {Rajalakshmi Krishnamurthi and Raghav Maheshwari and Rishabh Gulati},
  title     = {Deploying Deep Learning Models via {IOT} Deployment Tools},
  year      = {2019},
  month     = {aug},
  publisher = {{IEEE}},
  doi       = {10.1109/ic3.2019.8844946},
  groups    = {Start set, Selected from start set},
  relevance = {relevant},
}

@Article{Matsui2020,
  author    = {Matsui, Beatriz Mayumi Andrade and Goya, Denise Hideko},
  title     = {Application of DevOps in the improvement of machine learning processes},
  year      = {2020},
  copyright = {Creative Commons Attribution 4.0 International},
  doi       = {10.5281/ZENODO.4318113},
  groups    = {Start set},
  keywords  = {devops, machine learning, software, improvement},
  language  = {en},
  publisher = {Zenodo},
}

@InProceedings{Hazelwood2018,
  author    = {Kim Hazelwood and Sarah Bird and David Brooks and Soumith Chintala and Utku Diril and Dmytro Dzhulgakov and Mohamed Fawzy and Bill Jia and Yangqing Jia and Aditya Kalro and James Law and Kevin Lee and Jason Lu and Pieter Noordhuis and Misha Smelyanskiy and Liang Xiong and Xiaodong Wang},
  title     = {Applied Machine Learning at Facebook: A Datacenter Infrastructure Perspective},
  year      = {2018},
  month     = {feb},
  publisher = {{IEEE}},
  doi       = {10.1109/hpca.2018.00059},
  groups    = {Start set, Selected from start set},
  relevance = {relevant},
}

@InProceedings{Chen2020,
  author    = {Andrew Chen and Andy Chow and Aaron Davidson and Arjun DCunha and Ali Ghodsi and Sue Ann Hong and Andy Konwinski and Clemens Mewald and Siddharth Murching and Tomas Nykodym and Paul Ogilvie and Mani Parkhe and Avesh Singh and Fen Xie and Matei Zaharia and Richard Zang and Juntai Zheng and Corey Zumar},
  booktitle = {Proceedings of the Fourth International Workshop on Data Management for End-to-End Machine Learning},
  title     = {Developments in {MLflow}},
  year      = {2020},
  month     = {jun},
  publisher = {{ACM}},
  abstract  = {MLflow is a popular open source platform for managing ML development, including experiment tracking, reproducibility, and deployment. In this paper, we discuss user feedback collected since MLflow was launched in 2018, as well as three major features we have introduced in response to this feedback: a Model Registry for collaborative model management and review, tools for simplifying ML code instrumentation, and experiment analytics functions for extracting insights from millions of ML experiments.},
  doi       = {10.1145/3399579.3399867},
  groups    = {Start set, Selected from start set},
  relevance = {relevant},
  subtitle  = {A System to Accelerate the Machine Learning Lifecycle},
}

@Article{Jackson2019,
  author    = {Stuart Jackson and Maha Yaqub and Cheng-Xi Li},
  title     = {The Agile Deployment of Machine Learning Models in Healthcare},
  year      = {2019},
  month     = {jan},
  volume    = {1},
  doi       = {10.3389/fdata.2018.00007},
  groups    = {Start set},
  publisher = {Frontiers Media {SA}},
}

@InProceedings{Li2017,
  author    = {Li, Li Erran and Chen, Eric and Hermann, Jeremy and Zhang, Pusheng and Wang, Luming},
  booktitle = {Proceedings of The 3rd International Conference on Predictive Applications and APIs},
  title     = {Scaling Machine Learning as a Service},
  year      = {2017},
  editor    = {Hardgrove, Claire and Dorard, Louis and Thompson, Keiran and Douetteau, Florian},
  month     = {11--12 Oct},
  pages     = {14--29},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  volume    = {67},
  abstract  = {Machine learning as a service (MLaaS) is imperative to the success of many companies as they need to gain business intelligence from big data. Building a scalable MLaaS for mission-critical and real-time applications is a very challenging problem. In this paper, we present the scalable MLaaS we built for Uber that operates globally. We focus on several scalability challenges. First, how to scale feature computation for many machine learning use cases. Second, how to build accurate models using global data and account for individual city or region characteristics. Third, how to enable scalable model deployment and real-time serving for hundreds of thousands of models across multiple data centers. Our technical solutions are the design and implementation of a scalable feature computing engine and feature store, a framework to manage and train a hierarchy of models as a single logical entity, and an automated one-click deployment system and scalable real-time serving service.},
  groups    = {Backward snowballing},
  pdf       = {http://proceedings.mlr.press/v67/li17a/li17a.pdf},
  url       = {https://proceedings.mlr.press/v67/li17a.html},
}

@InProceedings{Baylor2017,
  author    = {Denis Baylor and Eric Breck and Heng-Tze Cheng and Noah Fiedel and Chuan Yu Foo and Zakaria Haque and Salem Haykal and Mustafa Ispir and Vihan Jain and Levent Koc and Chiu Yuen Koo and Lukasz Lew and Clemens Mewald and Akshay Naresh Modi and Neoklis Polyzotis and Sukriti Ramesh and Sudip Roy and Steven Euijong Whang and Martin Wicke and Jarek Wilkiewicz and Xin Zhang and Martin Zinkevich},
  title     = {{TFX}},
  year      = {2017},
  month     = {aug},
  publisher = {{ACM}},
  doi       = {10.1145/3097983.3098021},
  groups    = {Backward snowballing},
}

@Article{Garcia2020,
  author    = {Alvaro Lopez Garcia and Jesus Marco De Lucas and Marica Antonacci and Wolfgang Zu Castell and Mario David and Marcus Hardt and Lara Lloret Iglesias and Germen Molto and Marcin Plociennik and Viet Tran and Andy S. Alic and Miguel Caballer and Isabel Campos Plasencia and Alessandro Costantini and Stefan Dlugolinsky and Doina Cristina Duma and Giacinto Donvito and Jorge Gomes and Ignacio Heredia Cacha and Keiichi Ito and Valentin Y. Kozlov and Giang Nguyen and Pablo Orviz Fernandez and Zdenek Sustr and Pawel Wolniewicz},
  title     = {A Cloud-Based Framework for Machine Learning Workloads and Applications},
  year      = {2020},
  pages     = {18681--18692},
  volume    = {8},
  doi       = {10.1109/access.2020.2964386},
  groups    = {Backward snowballing},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@InProceedings{Crankshaw2017,
  author    = {Daniel Crankshaw and Xin Wang and Guilio Zhou and Michael J. Franklin and Joseph E. Gonzalez and Ion Stoica},
  booktitle = {14th {USENIX} Symposium on Networked Systems Design and Implementation ({NSDI} 17)},
  title     = {Clipper: A Low-Latency Online Prediction Serving System},
  year      = {2017},
  address   = {Boston, MA},
  month     = mar,
  pages     = {613--627},
  publisher = {{USENIX} Association},
  groups    = {Backward snowballing},
  isbn      = {978-1-931971-37-9},
  url       = {https://www.usenix.org/conference/nsdi17/technical-sessions/presentation/crankshaw},
}

@InCollection{Lwakatare2019,
  author    = {Lucy Ellen Lwakatare and Aiswarya Raj and Jan Bosch and Helena Holmström Olsson and Ivica Crnkovic},
  publisher = {Springer International Publishing},
  title     = {A Taxonomy of Software Engineering Challenges for Machine Learning Systems: An Empirical Investigation},
  year      = {2019},
  pages     = {227--243},
  doi       = {10.1007/978-3-030-19034-7_14},
  groups    = {Backward snowballing},
}

@InProceedings{Bernardi2019,
  author    = {Lucas Bernardi and Themistoklis Mavridis and Pablo Estevez},
  title     = {150 Successful Machine Learning Models},
  year      = {2019},
  month     = {jul},
  publisher = {{ACM}},
  doi       = {10.1145/3292500.3330744},
  groups    = {Backward snowballing},
}

@InProceedings{Yadwadkar2019,
  author    = {Neeraja J. Yadwadkar and Francisco Romero and Qian Li and Christos Kozyrakis},
  title     = {A Case for Managed and Model-less Inference Serving},
  year      = {2019},
  month     = {may},
  publisher = {{ACM}},
  doi       = {10.1145/3317550.3321443},
  groups    = {Forward snowballing},
}

@InProceedings{Chahal2020,
  author    = {Dheeraj Chahal and Ravi Ojha and Sharod Roy Choudhury and Manoj Nambiar},
  title     = {Migrating a Recommendation System to Cloud Using {ML} Workflow},
  year      = {2020},
  month     = {apr},
  publisher = {{ACM}},
  doi       = {10.1145/3375555.3384423},
  groups    = {Forward snowballing},
}

@InProceedings{Choi2021,
  author    = {Yujeong Choi and Yunseong Kim and Minsoo Rhu},
  title     = {Lazy Batching: An {SLA}-aware Batching System for Cloud Machine Learning Inference},
  year      = {2021},
  month     = {feb},
  publisher = {{IEEE}},
  doi       = {10.1109/hpca51647.2021.00049},
  groups    = {Forward snowballing},
}

@InProceedings{Zhang2020,
  author    = {Jeff Zhang and Sameh Elnikety and Shuayb Zarar and Atul Gupta and Siddharth Garg},
  booktitle = {12th {USENIX} Workshop on Hot Topics in Cloud Computing (HotCloud 20)},
  title     = {Model-Switching: Dealing with Fluctuating Workloads in Machine-Learning-as-a-Service Systems},
  year      = {2020},
  month     = jul,
  publisher = {{USENIX} Association},
  groups    = {Forward snowballing},
  url       = {https://www.usenix.org/conference/hotcloud20/presentation/zhang},
}

@InProceedings{Rausch2019,
  author    = {Thomas Rausch and Schahram Dustdar},
  title     = {Edge Intelligence: The Convergence of Humans, Things, and {AI}},
  year      = {2019},
  month     = {jun},
  publisher = {{IEEE}},
  doi       = {10.1109/ic2e.2019.00022},
  groups    = {Forward snowballing},
}

@Article{Paeaekkoenen2020,
  author    = {Pekka Pääkkönen and Daniel Pakkala and Jussi Kiljander and Roope Sarala},
  title     = {Architecture for Enabling Edge Inference via Model Transfer from Cloud Domain in a Kubernetes Environment},
  year      = {2020},
  month     = {dec},
  number    = {1},
  pages     = {5},
  volume    = {13},
  doi       = {10.3390/fi13010005},
  groups    = {Forward snowballing},
  publisher = {{MDPI} {AG}},
}

@InProceedings{Rausch2019a,
  author    = {Thomas Rausch and Waldemar Hummer and Vinod Muthusamy and Alexander Rashed and Schahram Dustdar},
  booktitle = {2nd {USENIX} Workshop on Hot Topics in Edge Computing (HotEdge 19)},
  title     = {Towards a Serverless Platform for Edge {AI}},
  year      = {2019},
  address   = {Renton, WA},
  month     = jul,
  publisher = {{USENIX} Association},
  groups    = {Forward snowballing},
  url       = {https://www.usenix.org/conference/hotedge19/presentation/rausch},
}

@InProceedings{Gupta2020,
  author    = {Nitu Gupta and Katpagavalli Anantharaj and Karthikeyan Subramani},
  title     = {Containerized Architecture for Edge Computing in Smart Home : A consistent architecture for model deployment},
  year      = {2020},
  month     = {jan},
  publisher = {{IEEE}},
  doi       = {10.1109/iccci48352.2020.9104073},
  groups    = {Forward snowballing},
}

@InProceedings{Peticolas2019,
  author    = {Devon Peticolas and Russell Kirmayer and Deepak Turaga},
  title     = {M{\'{\i}}mir: Building and Deploying an {ML} Framework for Industrial {IoT}},
  year      = {2019},
  month     = {nov},
  publisher = {{IEEE}},
  doi       = {10.1109/icdmw.2019.00065},
  groups    = {Forward snowballing},
}

@InProceedings{Richins2020,
  author    = {Daniel Richins and Dharmisha Doshi and Matthew Blackmore and Aswathy Thulaseedharan Nair and Neha Pathapati and Ankit Patel and Brainard Daguman and Daniel Dobrijalowski and Ramesh Illikkal and Kevin Long and David Zimmerman and Vijay Janapa Reddi},
  title     = {Missing the Forest for the Trees: End-to-End {AI} Application Performance in Edge Data Centers},
  year      = {2020},
  month     = {feb},
  publisher = {{IEEE}},
  doi       = {10.1109/hpca47549.2020.00049},
  groups    = {Forward snowballing},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Start set\;0\;1\;0xccffffff\;\;Papers that are part of the snowballing start set\;;
1 StaticGroup:Selected from start set\;0\;1\;0x669999ff\;\;\;;
1 StaticGroup:Backward snowballing\;0\;1\;0x00ff00ff\;\;\;;
1 StaticGroup:Forward snowballing\;0\;1\;0xff00ffff\;\;\;;
}
