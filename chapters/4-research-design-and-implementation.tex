\chapter{Research Design and Implementation}
\label{ch:research_design_and_implementation}
This chapter will discuss the motivation, design and implementation of the SLR.
The chapter is structured as follows.
In \cref{sec:research_motivation} the impact and usefulness of the study is argued.
\cref{sec:research_questions} presents the research questions of the study.
\cref{sec:research_method} outlines the research method and design of the study.
Finally, \cref{sec:research_implementation} accounts for how the study was conducted.

\section{Research Motivation}
\label{sec:research_motivation}
As outlined in \cref{ch:background}, industry adoption of ML is still in its early stages and rapidly growing.
The SE aspect of ML is an active field of research, with the vast majority of work having been done only in the past five years.
As reported by earlier literature studies in the field (see \cref{ch:related_work}), deployment of ML is an area which presents real challenges to practitioners.
Tackling deployment challenges requires adopting good practices as well as utilizing suitable tooling.
Much of the earlier work has largely had a broad scope, with goals of mapping out broad SE challenges and practices for ML.
Further, much of the earlier work has had a focus on reviewing the academic literature, ignoring the vast body of practitioner knowledge found in the GL.
To summarize, this study is motivated by two key factors.
\begin{itemize}
    \item Researching \acrshort{ml} deployment in-depth, and not as part of a broader study of SE for ML.
    \item Including more practitioner knowledge in the form of GL.
    \item Putting more focus on tooling and infrastructure by identifying what needs are fulfilled by current tooling and what is missing from tooling.
\end{itemize}

\section{Research Questions}
\label{sec:research_questions}
The overarching research question of this study is "\textbf{What is the state of the art in ML deployment?}".
The focus will be on tooling and trying to identify feature gaps reported in studies where model deployment is discussed.
To support the main research question, four subquestions have been defined:
\begin{itemize}
    \item \textbf{RQ1: How are ML models deployed in the state of the art?}
    \item \textbf{RQ2: What are the main challenges and pain points in ML model deployment?}
    \item \textbf{RQ3: What tools and infrastructure are used to deploy ML models?}
    \item \textbf{RQ4: What are the feature gaps in the tooling and infrastructure used to deploy ML models?}
\end{itemize}
The working definition of \emph{deployment} in this paper is outlined in \cref{sec:deploying_ml_systems}.

\section{Research Method and Design}
\label{sec:research_method}
This study is a \acrfull{mlr} based on the guidelines of \textcite{Kitchenham07guidelinesfor} and \textcite{Garousi2019}.

\subsection{Search Strategy}
\subsubsection{White Literature}
Initial string-based searches in digital libraries failed to produce adequately relevant articles for the topic at hand, thus motivating the use of snowballing as an alternative approach for identifying candidate papers.
The snowballing procedure followed the process proposed by \textcite{Wohlin2014}, with the exception that forward and backward snowballing were limited to a single iteration each.
Fordward snowballing will be conducted by using the \emph{cited by} functionality of Google Scholar\footnote{\url{https://scholar.google.com/}}.

\subsubsection{Grey Literature}
Pilot searches using Google revealed that adequately relevant and recent results were found using the search string "mlops deployment".
Based on the outlined GL search guidelines in \cite{Garousi2016}, the Top N-approach was selected with the search string "mlops deployment" and $N=100$.

\subsection{Study Selection}
I will perform selection, while my supervisor Jingyue Li will review my selection (?).
Studies will be selected based on the criteria found in \cref{tab:selection_criteria}, according to the type of literature (\acrshort{wl}/\acrshort{gl}).
\begin{table}[h]
    \centering
    \begin{tabular}{l|p{0.4\linewidth}|p{0.4\linewidth}}
         Literature type & \acrshort{wl} & \acrshort{gl}  \\
         \hline
        Inclusion criteria & \begin{itemize}
    \item Written in English
    \item Published in a peer-reviewed journal, conference or workshop
    \item Published after 2010
    \item Discusses one of the following aspects of machine learning deployment: challenges, solutions, tooling, processes, requirements
    \item Available online
\end{itemize} & \begin{itemize}
    \item Written in English
    \item Published after 2010
    \item Discusses one of the following aspects of machine learning deployment: challenges, solutions, tooling, processes, requirements
    \item Available online
\end{itemize} \\
         Exclusion criteria & \begin{itemize}
             \item One of the inclusion criteria is not satisfied
         \end{itemize}  & \begin{itemize}
             \item One of the inclusion criteria is not satisfied
         \end{itemize} \\
    \end{tabular}
    \caption{Selection criteria for \acrfull{wl} and \acrfull{gl}.}
    \label{tab:selection_criteria}
\end{table}

\subsection{Study Quality Assessment}
The quality of both \acrshort{wl} and \acrshort{gl} sources will be assessed using the criteria found in \cref{tab:study_quality_criteria}, adapted from criteria used by \cite{Giray2021} and suggested by \cite{Garousi2016}.
\begin{table}[h]
    \centering
    \begin{tabular}{l c c}
        Criteria & Empirical & Non-empirical \\
        \hline
        Does the author have authority on the subject? & X & X \\
        Does the source have a clearly stated aim? & X & X \\
        Is the author free of any vested interests? & X & X \\
        Have key related GL or WL sources been linked to/discussed? & X & X \\
        Is relevance (to industry or academia) discussed? & X & X \\
        Does the source have a stated methodology? & X &  \\
        Are any threats to validity clearly stated? & X & \\
    \end{tabular}
    \caption{Study quality assessment criteria for empirical and non-empirical sources, indicated by \emph{X}.}
    \label{tab:study_quality_criteria}
\end{table}
Each sub-point is awarded 1 for \emph{yes}, 0.5 for \emph{partly} and 0 for \emph{no}.
Sources with an average of 0.5 points or less are excluded.

\subsection{Data Extraction}
\label{sec:method:data_extraction}
In order to answer the research questions, sufficient data must be gathered from the literature.
Thus, the following data extraction form was designed:

% \begin{description}
%     \item[Author] Name of author(s)
%     \item[Year] Publication year
%     \item[Context] Description of deployment context where necessary
%     \item[Achievement] Main achievement of the study
%     \item[Process] Description of the deployment process (RQ1)
%     \item[Tools \& infrastructure] Tools and infrastructure used for deployment (RQ1, RQ3)
%     \item[Challenges] Deployment challenges reported (RQ2)
%     \item[Solutions] Implemented or proposed solutions to reported problems (RQ1, RQ2)
%     \item[Requirements] Reported requirements for deployment process, tooling and infrastructure (RQ4)
%     \item[Gaps] Reported unmet requirements in infrastructure or tooling (RQ4)
%     \item[Other] Any other notes
% \end{description}

\begin{table}[]
    \centering
    \begin{tabular}{l|p{8.5cm}}
        Field & Explanation\\
        \hline
        Author & Name of author(s)  \\
        Publication year & Year of publication \\
        Context & Description of deployment context where necessary \\
        Achievement & Main achievement of the study \\
        Process & Description of the deployment process (RQ1) \\
        Tools \& infrastructure & Tools and infrastructure used for deployment (RQ1, RQ3) \\
        Challenges & Deployment challenges reported (RQ2) \\
        Solutions & Implemented or proposed solutions to reported problems (RQ1, RQ2) \\
        Requirements & Reported requirements for deployment process, tooling and infrastructure (RQ4) \\
        Gaps & Reported unmet requirements, open problems and proposed research directions in infrastructure or tooling  (RQ4) \\
        Other & Any other notes \\
    \end{tabular}
    \caption{Data extraction form with clarification of the content for each field.}
    \label{tab:data_extraction_form}
\end{table}

\subsection{Data Synthesis}
The data extraction form is designed to extract the information required to answer the research question.
As most papers will likely not address all research questions that this review is concerned with, the qualitative approach of \textit{line of argument} synthesis will be used to synthesize the data, as suggested in \cite{Kitchenham07guidelinesfor}.

\section{Research Implementation}
\label{sec:research_implementation}
Selection, quality assessment and data extraction was conducted in an online spreadsheet, which can be found [ref].

\subsection{Search}
\subsubsection{White Literature}
In order to start the WL snowballing, an initial set of studies was assembled from manual search, as well as looking at the reference lists of earlier work, such as \cite{John2021} and \cite{MartinezFernandez2021}.
The start set can be found in table [table].
The WL study selection criteria found in \cref{tab:selection_criteria} were applied to the start set, resulting in [table].
From the start set of 19 papers, 8 satisfied the selection criteria and minimum study quality score, and were thus selected for review and further snowballing.

Backward snowballing from the 8 selected papers provided an additional 21 candidate papers based on skimming title/abstract/content of all referred papers from the start set.
Of the 21 candidate papers, 6 papers satisfied the selection criteria and minimum study quality criteria.

Forward snowballing from the start set yielded 29 initial candidate papers.
After applying selection criteria, 10 candidate papers remained, of which all satisfied the minimum study quality criteria.

The total number of papers to review was thus 24.

\subsubsection{Grey Literature}

\subsection{Data Extraction}
Data extraction proceeded by reading the literature and extracting information as described in \cref{sec:method:data_extraction} and entering the data in a spreadsheet.

\subsection{Data Synthesis}
Data synthesis was performed with the help of TreeSheets \footnote{\url{https://strlen.com/treesheets/}}, a hierarchical spreadsheet application.
For each research question, relevant extracted data for each author was entered in the hierarchy.
The data pieces were then coded according to their content.
Lastly, the hierarchy swap feature was used to reorganize the data from being author-oriented to being code-oriented.